# 🎬 Lesson 1: Introduction to Azure Data Factory

⏱️ Timestamp: 00:00 - 13:35

## 🔑 Key Concepts
- Azure Data Factory (ADF) is a cloud-based data integration service.
- Enables data movement, transformation, scheduling, and monitoring.
- Thus its a cloud based ETL/ELT tool.
- Has connectors for all the sources(SQLdb, csv files, api, http) and also for the destinations(Azure data lake, S3, Azure sql db ,   
  Dataverse,etc). Thus 'E' and 'L' is done.
- For 'T' -> Has Data Flows = viz the transformation functionalities which the ADF possess. Spark clusters run behind the Data flows.

## 🛠️ Components Introduced
- **Linked Service** – Connects to sources like Azure SQL, Blob, etc.
- **Dataset** – Data structures like tables, files, etc.
- **Pipeline** – Collection of activities like Copy, Lookup.

## 💬 Quotes/Concepts from Ansh:
> "ADF is there in Synapse analytics and fabric. ADF is always there."

## 📌 My Observations
- GUI makes it easy for non-coders to build pipelines.
- Great for enterprise-scale ETL workflows.

## 🧠 To Revisit
- Difference between Integration Runtime vs Linked Service

